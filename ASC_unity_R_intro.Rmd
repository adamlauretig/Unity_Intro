---
title: "Introduction to R on the ASC Unity Cluster"
author: "Adam Lauretig"
date: "April 28, 2017"
output:
  word_document: default
  html_document: default
---

## ASC Unity Cluster

Ohio State ASC tech has recent made the [Unity high-performance](https://osuasc.teamdynamix.com/TDClient/KB/?CategoryID=4582 "Unity") cluster available to everyone, with up to 24 cores available for your high performance computing needs.  However, access the cluster and running R code in it can be confusing for those not familiar with unix systems. To spare you 3 days of beating your head against the wall and cursing the unix gods, I've put together the following introduction to using R on the unix cluster.  In this document, I will: introduce the basics of interacting with Unity; illustrate how to load packages in the Unity environment; discuss how to write the bash files for running code to take advantage of the parallel environment; and demonstrate how to upload a file, run a batch R script, and download the results.

## Connecting to the Unity cluster

On a Mac, to connect to the Unity cluster, open the terminal, and type:

```{bash, eval=FALSE}
ssh -l username.N unity.asc.ohio-state.edu

```
where username.N is your Ohio State name.number.  You'll be prompted for your OSU password, which you should enter. If you're on a Windows computer, you'll use PuTTy to connect to the Unity cluster.  If you log in, you will see the following:
```{bash, eval = FALSE}
-----------------------------------------
Welcome to Unity.

This is a college-wide resource managed by ASCTech

Information on how to use the Unity Cluster:
http://go.osu.edu/unityhelp

For assistance please email asctech@osu.edu
or submit request to: http://go.osu.edu/unitysubmit
-----------------------------------------


[username.N@unity-1 ~]$ 

```


## In the Unity Environment
To list the current contents of your working directory, type: 
```{bash, eval = FALSE}
ls
```

at the prompt. We then want to know which softwares we can use, which are in *modules*.  To see the modules available, type:
```{bash, eval = FALSE}
module avail
```

and to load the R module, type:
```{bash, eval = FALSE}
module load intel R
```
since, R depends on the intel module. To open R, type
```{bash, eval = FALSE}
R
```
which will open an R command line, from where you can, for example, install packages.  To see the currently installed packages, type:
```{r, eval = FALSE}
installed.packages()
```
which will generate a reasonably long list of installed packages.  While we're here, let's install data.table and parallel, since we'll be using them later:
```{r, eval = FALSE}
install.packages("data.table", repos = "http://cran.case.edu" )
install.packages("parallel", repos = "http://cran.case.edu" )

```
This will take a few seconds, and then, you can load the data.table library, which should work:
```{r, eval = FALSE}
library(data.table)
```
This is all we'll need for now, so quit R, and don't save the workspace image:
```{r, eval = FALSE}
q()
```

Now, log out of the unity environment, and type:
```{bash, eval = FALSE}
logout
```
which will return your terminal to the original directory.  Log out now, we'll set up our code on the local computer, and then send it to the cluster for batch processing.

## Setting up Code to run in a batch setting

I've provided some sample data, and a sample script (`fake_data.rdata`, and `toy_function.R` respectively), which paste a number and letter together and save them to a data frame. To run this as a batch process, where we take advantage of the parallel computing possibilities we will need to write a `.pbs` file to schedule our job on the cluster, more details [here](https://osuasc.teamdynamix.com/TDClient/KB/ArticleDet?ID=23180 "Unity cluster") and [here](https://www.osc.edu/content/batch-tutorial "OSC tutorial").

An example batch script would be 
```{bash pbs_file, eval=FALSE}
#!/bin/bash
#PBS -l walltime=00:10:00
#PBS -l nodes=1:ppn=3
#PBS -N toy_bash_job
#PBS -j oe 
#PBS -m abe
#PBS -M username.N@osu.edu


#COMMANDS TO RUN
module load intel/16.0.3 
module load R/3.3.2 
~/toy_function.R
```
where walltime is the amount of time you expect to use, nodes and ppn are the number of cores (2 each with 12 possible cores), `-N` is the name of the job, `-j oe` writes errors to standard output, `-m abe` tells the cluster to email you (abort, begin, end), and `-M` is the address to email you.  

Under `#COMMANDS TO RUN`, `module load intel/16.0.3` calls the necessary intel compiler, and `module load R/3.3.2` is loads `R`, to batch execute the script.  Just using `module load intel R` in the bash script causes the cluster to throw esoteric errors.  Either one can learn a great deal about unix file structures to solve this problem, or copy and paste the above code.  I recommend the second approach.

To write a `.pbs` file on a Mac, open textedit (or another plain-text editor), write the commands for your bash file, uncheck "hide extension," uncheck "if no extension is provided use '.txt'," and change the file extension to `.pbs`.

The function we're testing is simple: given 10000 letters, paste its location in a list, and underscore, and then the letter, and output a data.table. The setup looks like this:
```{r toy_function, eval = FALSE}
library(parallel)
library(data.table)
load("~/fake_data.rdata") # note that we're using short filepaths
paste_number_letter <- function(i = NULL, letter_vector = NULL){
  data.table(paste0(letter_vector[i], "_", i))
}
length_of_letters <- length(fake_data)
function_out <- mclapply(1:length_of_letters, paste_number_letter, 
  letter_vector = fake_data, mc.cores = 3)
toy_dt <- rbindlist(function_out)
save(toy_dt, file = "~/toy_dt.rdata")
```
where the parallel library supplies the `mclapply` function, for which, we tell it to use three cores, in `mc.cores`.  The file path for loading and saving is just `~/`, since we'll put everything in the same directory.

## Uploading Files

To upload our files, we'll use the `scp` command in the terminal. This has the format `scp [source filepath] [target file path]`:

```{bash scp_example, eval = FALSE}
scp ~/data/Unity_intro/demo_pbs.pbs username.N@unity.asc.ohio-state.edu:/home/username.N

scp ~/data/Unity_intro/fake_data.rdata username.N@unity.asc.ohio-state.edu:/home/username.N

scp ~/data/Unity_intro/toy_function.R username.N@unity.asc.ohio-state.edu:/home/username.N

```
where `~/data/Unity_intro/` is the local path, and `username.N@unity.asc.ohio-state.edu:/home/username.N` is the path on the cluster.

## Running batch code

We'll now log back into the unity cluster, and run our code with
```{bash run_pbs, eval = FALSE}
qsub demo_pbs.pbs
```

Which will email us when the job starts, and ends. If the email you receive when is ends has `Exit_status=0`, the code ran successfully, and if it has `Exit_status=127`, it failed.  To see the error message if it fails, type

```{bash check_errors, eval = FALSE}
cat toy_bash_job.o[JOBNUM]
```
where `toy_bash_job` is the name of the job, and `[JOBNUM]` is the job number the cluster assigns. An example filename might be `toy_bash_job.o1234`. `cat` tells the terminal to print the file to the screen.

If it works, `toy_dt.rdata` with appear when we type `ls`, and an output file with the job name and number will appear as well.

## Download the Result

To download the result back to your computer, we'll use `scp` in reverse
```{bash scp_download, eval = FALSE}
scp username.N@unity.asc.ohio-state.edu:/home/username.N/toy_dt.rdata ~/data/Unity_intro/ 

```
which we can then open in R.

